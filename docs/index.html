<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: Problem statement</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Problem statement </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a> We consider the classical unconstrained non-linear optimization problem</p>
<p>$$ \min_{x \in \mathbb{R}^n} f(x), $$</p>
<p>where $ f : \mathbb{R}^n \to \mathbb{R} $ is assumed to be sufficiently smooth (typically at least twice continuously differentiable). A standard second-order method for this problem is <b>Newtonâ€™s method</b>, whose iteration can be written as</p>
<p>$$ H_k \Delta_k = -\nabla f(x_k), \quad x_{k+1} = x_k + \Delta_k, $$</p>
<p>where $H_k$ is the Hessian of $f$ at $x_k$ and $\nabla f(x_k)$ is the gradient. Newtonâ€™s method can achieve quadratic convergence near the solution but it has some drawbacks:</p>
<ul>
<li>computing and storing the full Hessian $H_k \in \mathbb{R}^{n \times n}$ is expensive for large $n$;</li>
<li>solving a linear system with $H_k$ at each iteration is also costly;</li>
<li>global convergence typically requires safeguards, such as <b>line-search</b> or <b>trust-region</b> strategies.</li>
</ul>
<p>For moderately large or large-scale problems, forming and storing the full Hessian quickly becomes prohibitive, and more efficient approaches are required. <b>Quasi-Newton methods</b> address this by building and updating an approximation of the Hessian (or its inverse) using only gradient information, while still retaining superlinear convergence under suitable conditions.</p>
<p>This project focuses on two such methods: <b><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a></b> and <b>L-BFGS</b>.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md2"></a>
Algorithms</h1>
<p>This project implements/analyzes Quasi-Newton methods for unconstrained non-linear optimization.</p>
<h2><a class="anchor" id="autotoc_md3"></a>
BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno)</h2>
<p><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a> is an iterative method for solving unconstrained non-linear optimization problems. As a Quasi-Newton method, it approximates the Hessian matrix of the objective function using gradient evaluations.</p>
<ul>
<li><b>Mechanism:</b> It maintains a full dense approximation of the (inverse) Hessian matrix and updates it at each step so that the <b>secant equation</b> is satisfied. The search direction is obtained by solving a linear system involving this matrix.</li>
<li><b>Performance:</b> It offers superlinear convergence under standard assumptions and is generally robust in practice.</li>
<li><b>Memory cost:</b> $O(n^2)$, where $n$ is the number of variables. This makes it suitable for small to medium-sized problems, where storing an $n \times n$ matrix is still feasible.</li>
</ul>
<h2><a class="anchor" id="autotoc_md4"></a>
L-BFGS (Limited-memory BFGS)</h2>
<p>L-BFGS is an optimization algorithm in the family of Quasi-Newton methods that approximates the <a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a> algorithm using a limited amount of memory.</p>
<ul>
<li><b>Mechanism:</b> Instead of storing the full $n \times n$ inverse Hessian matrix, it stores only a small number of vector pairs $(s_k, y_k)$ that implicitly represent the quasi-Newton approximation. It maintains a history of the past $m$ updates (where $m$ is typically small, e.g., 5â€“20) and uses the <b>two-loop recursion</b> to apply the inverse Hessian approximation to a vector.</li>
<li><b>Performance:</b> It enjoys similar convergence properties to full <a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a> in many cases, though it can be slightly less robust on very ill-conditioned problems.</li>
<li><b>Memory cost:</b> $O(mn)$, which makes it well suited for large-scale problems with thousands or millions of variables, as the memory footprint grows only linearly with the problem dimension.</li>
</ul>
<hr  />
<h2><a class="anchor" id="autotoc_md6"></a>
Organization of the code</h2>
<p>The directory structure is as follows:</p>
<div class="fragment"><div class="line">./Project</div>
<div class="line">  â”œâ”€â”€ build/</div>
<div class="line">  â”œâ”€â”€ lib/</div>
<div class="line">  â”œâ”€â”€ paper/</div>
<div class="line">  â””â”€â”€ src/</div>
</div><!-- fragment --><ul>
<li><code>build</code> contains the output of CMAKE</li>
<li><code>lib</code> contains the external libraries</li>
<li><code>paper</code>containes the academic literature provided</li>
<li><code>src</code> contains all the C++ code to be compiled</li>
</ul>
<h2><a class="anchor" id="autotoc_md7"></a>
Compiling</h2>
<p>To compile we use CMAKE, from the <code>Project</code> directory run:</p>
<div class="fragment"><div class="line">mkdir build</div>
<div class="line">cd build</div>
<div class="line">cmake ..</div>
<div class="line">make</div>
</div><!-- fragment --> <h3><a class="anchor" id="autotoc_md8"></a>
Run</h3>
<p>To run the test from the <code>build</code> directory: </p><div class="fragment"><div class="line">./test</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md9"></a>
Documentation</h2>
<p>The full API documentation generated with Doxygen is available here:</p>
<p>ðŸ‘‰ <a href="https://amsc-25-26.github.io/lfbgs-1-lbfgs/"><b>Open the documentation</b></a></p>
<h2><a class="anchor" id="autotoc_md10"></a>
Tests</h2>
<p>The test suite evaluates the performance of <a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a>, L-BFGS, <a class="el" href="classNewton.html" title="Newton minimizer (full Newton) for unconstrained optimization.">Newton</a>'s method, and a hybrid BFGS+GMRES variant on three benchmark optimization problems:</p>
<h3><a class="anchor" id="autotoc_md11"></a>
1. &lt;strong&gt;Rosenbrock Function&lt;/strong&gt;</h3>
<p><img src="img/Rosenbrock_contour.svg.png" alt="Rosenbrock contour plot" class="inline"/></p>
<p>The Rosenbrock function is a classic test problem for optimization algorithms. It features a long, narrow parabolic valley that makes it challenging for algorithms to navigate efficiently.</p>
<p><b>Characteristics:</b></p><ul>
<li>Non-convex function with a global minimum at $(1, 1, \ldots, 1)$</li>
<li>Dimension tested: $n = 4$</li>
<li>Convergence criterion: gradient norm $\leq 10^{-10}$</li>
<li>Tolerance: $10^{-12}$, max iterations: $4000$</li>
</ul>
<hr  />
<h3><a class="anchor" id="autotoc_md13"></a>
2. &lt;strong&gt;Ackley Function&lt;/strong&gt;</h3>
<p><img src="img/Ackley_contour_function.svg.png" alt="Ackley contour plot" class="inline"/></p>
<p>The Ackley function is a highly multimodal landscape with a single global minimum. It tests the algorithm's ability to explore and avoid being trapped in local minima.</p>
<p><b>Characteristics:</b></p><ul>
<li>Multimodal function with global minimum at the origin $(0, 0, \ldots, 0)$</li>
<li>Dimension tested: $n = 3$</li>
<li>Convergence criterion: gradient norm $\leq 10^{-9}$</li>
<li>Tolerance: $10^{-10}$, max iterations: $4000$</li>
</ul>
<hr  />
<h3><a class="anchor" id="autotoc_md15"></a>
3. &lt;strong&gt;Rastrigin Function&lt;/strong&gt;</h3>
<p><img src="img/Rastrigin_contour_plot.svg.png" alt="Rastrigin contour plot" class="inline"/></p>
<p>The Rastrigin function is highly oscillatory with many local minima, providing a severe test of robustness and global convergence capabilities.</p>
<p><b>Characteristics:</b></p><ul>
<li>Highly multimodal landscape with global minimum at the origin $(0, 0, \ldots, 0)$</li>
<li>Dimension tested: $n = 500$ (large-scale problem)</li>
<li>Convergence criterion: gradient norm $\leq 10^{-8}$</li>
<li>Tolerance: $10^{-9}$, max iterations: $5000$</li>
<li>This test demonstrates the scalability of L-BFGS and memory efficiency of the algorithms</li>
</ul>
<hr  />
<h3><a class="anchor" id="autotoc_md17"></a>
Test Implementation</h3>
<p>All tests are implemented in <a href="tests/main.cpp">tests/main.cpp</a> and use a flexible test suite framework that allows comparing multiple solver implementations side-by-side on the same benchmark problems. The solvers are evaluated based on:</p>
<ul>
<li><b>Convergence:</b> Whether the gradient norm reaches the specified tolerance</li>
<li><b>Solution accuracy:</b> How close the found solution is to the known global minimum</li>
<li><b>Iteration count:</b> Number of iterations required to converge</li>
<li><b>Memory efficiency:</b> Particularly important for the Rastrigin function test</li>
</ul>
<hr  />
<h3><a class="anchor" id="autotoc_md19"></a>
Performance Results</h3>
<p>The table below summarizes the performance of the four solvers across the three benchmark functions:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Function   </th><th class="markdownTableHeadNone">Solver   </th><th class="markdownTableHeadNone">Time (Î¼s)   </th><th class="markdownTableHeadNone">Iterations   </th><th class="markdownTableHeadNone">Tolerance    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Rosenbrock</b>   </td><td class="markdownTableBodyNone"><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a>   </td><td class="markdownTableBodyNone">2,728   </td><td class="markdownTableBodyNone">52   </td><td class="markdownTableBodyNone">$10^{-12}$    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a> + GMRES   </td><td class="markdownTableBodyNone">6,342   </td><td class="markdownTableBodyNone">52   </td><td class="markdownTableBodyNone">$10^{-12}$    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">L-BFGS   </td><td class="markdownTableBodyNone"><b>1,295</b>   </td><td class="markdownTableBodyNone">47   </td><td class="markdownTableBodyNone">$10^{-12}$    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"><a class="el" href="classNewton.html" title="Newton minimizer (full Newton) for unconstrained optimization.">Newton</a>   </td><td class="markdownTableBodyNone">18,024   </td><td class="markdownTableBodyNone">395   </td><td class="markdownTableBodyNone">$10^{-12}$    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Ackley</b>   </td><td class="markdownTableBodyNone"><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a>   </td><td class="markdownTableBodyNone">342   </td><td class="markdownTableBodyNone">7   </td><td class="markdownTableBodyNone">$10^{-10}$    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a> + GMRES   </td><td class="markdownTableBodyNone">644   </td><td class="markdownTableBodyNone">7   </td><td class="markdownTableBodyNone">$10^{-10}$    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">L-BFGS   </td><td class="markdownTableBodyNone"><b>80</b>   </td><td class="markdownTableBodyNone">5   </td><td class="markdownTableBodyNone">$10^{-10}$    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"><a class="el" href="classNewton.html" title="Newton minimizer (full Newton) for unconstrained optimization.">Newton</a>   </td><td class="markdownTableBodyNone">102   </td><td class="markdownTableBodyNone">3   </td><td class="markdownTableBodyNone">$10^{-10}$    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Rastrigin</b>   </td><td class="markdownTableBodyNone"><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a>   </td><td class="markdownTableBodyNone">251,197   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">$10^{-9}$    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a> + GMRES   </td><td class="markdownTableBodyNone"><b>45,107</b>   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">$10^{-9}$    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">L-BFGS   </td><td class="markdownTableBodyNone"><b>12,260</b>   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">$10^{-9}$    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"><a class="el" href="classNewton.html" title="Newton minimizer (full Newton) for unconstrained optimization.">Newton</a>   </td><td class="markdownTableBodyNone">647,068   </td><td class="markdownTableBodyNone">3   </td><td class="markdownTableBodyNone">$10^{-9}$   </td></tr>
</table>
<p><b>Key Observations:</b></p>
<ul>
<li><b>L-BFGS excels on Rosenbrock and Ackley functions</b>, being the fastest across these smooth, well-conditioned problems.</li>
<li><b><a class="el" href="classBFGS.html" title="BFGS (Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno) minimizer.">BFGS</a> + GMRES is competitive on the large-scale Rastrigin problem</b> ($n=500$), where the iterative solver avoids dense linear system solves.</li>
<li><b><a class="el" href="classNewton.html" title="Newton minimizer (full Newton) for unconstrained optimization.">Newton</a>'s method struggles on Rastrigin</b>, requiring many iterations due to the oscillatory landscape and the cost of Hessian computations at each step.</li>
<li><b>L-BFGS demonstrates superior scalability</b> on the large-scale Rastrigin test, where memory efficiency becomes critical. </li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
